## ğŸ” Deep Research SDK ğŸ¤–

A Python SDK that automates deep, multi-iteration research using AI agents + web search. It turns a single question into a structured report with sources. 

- **What you get**: AI-generated queries âœ real-time web results âœ concise analyses âœ follow-up loops âœ a final, well-structured report.
- **Powered by**: LiteLLM, DuckDuckGo Search (`ddgs`), and `rich` for a slick CLI.

---

### âœ¨ Features

- **ğŸ§  Multi-agent pipeline**: Query generation, web summarization, follow-up decisioning, synthesis.
- **ğŸ” Iterative research**: Decides if/when to dig deeper; runs multiple rounds automatically.
- **ğŸŒ Live web search**: DuckDuckGo for real-time sources, with basic scraping and summarization.
- **ğŸ“ Markdown reports**: Clear structure, headings, and sources list.
- **ğŸ›ï¸ Model-flexible**: Use any LiteLLM-supported model (OpenAI, Anthropic, etc.).
- **ğŸ“Ÿ Pretty CLI**: Live progress and panels via `rich`.

---

 

### âš™ï¸ Installation

```bash
git clone <repository-url>
cd deep-research-sdk
pip install .
```

Create a `.env` with your API keys:
```bash
echo "OPENAI_API_KEY=your_openai_api_key_here" > .env
# Optional:
# echo "ANTHROPIC_API_KEY=your_anthropic_api_key_here" >> .env
```

- Requires Python 3.11+.

---

### ğŸš€ Quick Start

#### CLI (interactive)
```bash
# Installed entrypoint (recommended)
deep-research-sdk research

# Or run directly from the repo
python deep_research_sdk/cli.py research

# Show version
deep-research-sdk -v

# Show help
deep-research-sdk -h
python deep_research_sdk/cli.py -h
```
Youâ€™ll be prompted for a topic. The tool will research it and print a Markdown report.

---

<details>
<summary>More details</summary>

### ğŸ—ï¸ Architecture at a glance

- `ResearchCoordinator` â€” orchestrates the full loop.
- `QueryAgent` â€” turns your topic into targeted search queries.
- `SearchAgent` â€” fetches a result, scrapes the page, summarizes it.
- `FollowUpAgent` â€” decides whether to continue and what to search next.
- `SynthesisAgent` â€” merges everything into a final report.

---

### ğŸ”¬ How it works

1. **ğŸ§­ Query generation** â€” Breaks your topic into focused queries.
2. **ğŸ” Web search** â€” Finds results via DuckDuckGo (`ddgs`).
3. **ğŸ§ª Page analysis** â€” Scrapes each result and summarizes with the model.
4. **ğŸ¤” Follow-up decision** â€” Decides whether to search again; generates follow-up queries if needed.
5. **ğŸ§µ Synthesis** â€” Produces a structured Markdown report with key findings and sources.

Note: By default, search pulls a small number of results per query to stay fast and focused.

---

### ğŸ“š API Reference

#### `ResearchCoordinator`
```python
ResearchCoordinator(
  model: str,
  query: str,
  max_iterations: int | None = 3
)
```

- **model**: Any LiteLLM-supported model ID (e.g., `"gpt-4o-mini"`, `"gpt-4"`, `"claude-3-sonnet"`).
- **query**: Your research topic/question.
- **max_iterations**: How many rounds the system may run.

Method:
- `await research() -> str` â€” Runs the full pipeline and returns a Markdown report.

---

### ğŸ§° Python examples

```python
import asyncio
from deep_research_sdk import ResearchCoordinator

async def main():
    coordinator = ResearchCoordinator(
        model="gpt-4o-mini",
        query="What are the latest developments in quantum computing?",
        max_iterations=3
    )
    report = await coordinator.research()
    print(report)

asyncio.run(main())
```

```python
import asyncio
from deep_research_sdk import ResearchCoordinator

async def run():
    rc = ResearchCoordinator(
        model="gpt-4",
        query="What are the current theories about dark matter and their implications?",
        max_iterations=3
    )
    report = await rc.research()
    with open("dark_matter_report.md", "w") as f:
        f.write(report)

asyncio.run(run())
```

---

### ğŸ§© Configuration

Set environment variables via `.env`:
```env
OPENAI_API_KEY=your_openai_api_key_here
# Optional (LiteLLM supports many providers)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
```

Supported model IDs include (but arenâ€™t limited to):
- `gpt-4o-mini` (great balance)
- `gpt-4`
- `gpt-3.5-turbo`
- `claude-3-sonnet`
- `claude-3-haiku`

---

### âœ… Dependencies

- `litellm` â€” model routing + unified client
- `pydantic` â€” typed responses from agents
- `rich` â€” styled CLI
- `ddgs` â€” DuckDuckGo search
- `requests`, `bs4` â€” basic scraping
- `python-dotenv` â€” env management

---

### ğŸ› ï¸ Troubleshooting

- âŒ Missing report? Ensure `OPENAI_API_KEY` (or other provider keys) is set.
- ğŸ•¸ï¸ Empty/odd summaries? Websites may block scraping; try different queries.
- ğŸ¢ Slow runs? Reduce `max_iterations`, or try a faster/cheaper model.
- ğŸŒ Network issues? Check firewall/proxy; `ddgs` requires outbound access.

</details>

### ğŸ“œ License

MIT License
